import pandas as pd
import numpy as np
import re
import string
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import warnings
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Suppress warnings
warnings.filterwarnings("ignore")

# Load datasets
fake_df = pd.read_csv("/kaggle/input/fake-and-real-news-dataset/Fake.csv")
true_df = pd.read_csv("/kaggle/input/fake-and-real-news-dataset/True.csv")

# Add labels
fake_df['label'] = 0  # Fake news
true_df['label'] = 1  # Real news

# Combine datasets
data = pd.concat([fake_df, true_df], axis=0).reset_index(drop=True)
data = data.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle dataset

# Drop unnecessary columns
data.drop(columns=['date', 'subject', 'title'], errors='ignore', inplace=True)

# **1. Dataset Distribution Visualization**
plt.figure(figsize=(6, 4))
sns.countplot(x=data['label'], palette=['red', 'blue'])
plt.xticks(ticks=[0, 1], labels=['Fake News', 'Real News'])
plt.xlabel("News Type")
plt.ylabel("Count")
plt.title("Distribution of Fake vs. Real News")
plt.show()

# Text preprocessing function
def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = text.translate(str.maketrans("", "", string.punctuation))  # Remove punctuation
    text = re.sub(r"\d+", "", text)  # Remove numbers
    text = re.sub(r"\s+", " ", text).strip()  # Remove extra spaces
    return text

# Apply text cleaning
data['text'] = data['text'].astype(str).apply(preprocess_text)

# **2. WordCloud for Most Common Words**
fake_text = " ".join(data[data['label'] == 0]['text'])
real_text = " ".join(data[data['label'] == 1]['text'])

plt.figure(figsize=(12, 5))

# Fake news WordCloud
plt.subplot(1, 2, 1)
wordcloud_fake = WordCloud(width=400, height=300, background_color="white").generate(fake_text)
plt.imshow(wordcloud_fake, interpolation="bilinear")
plt.axis("off")
plt.title("Most Common Words in Fake News")

# Real news WordCloud
plt.subplot(1, 2, 2)
wordcloud_real = WordCloud(width=400, height=300, background_color="white").generate(real_text)
plt.imshow(wordcloud_real, interpolation="bilinear")
plt.axis("off")
plt.title("Most Common Words in Real News")

plt.show()

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    data['text'], data['label'], test_size=0.2, random_state=42, stratify=data['label']
)

# **3. Creating a Pipeline (TF-IDF + Logistic Regression)**
model_pipeline = make_pipeline(
    TfidfVectorizer(stop_words='english', max_df=0.7),
    LogisticRegression()
)

# Train model
model_pipeline.fit(X_train, y_train)

# Save trained pipeline
joblib.dump(model_pipeline, "fake_news_pipeline.pkl")

# Predictions
y_pred = model_pipeline.predict(X_test)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# **4. Confusion Matrix Visualization**
plt.figure(figsize=(5, 4))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# **5. TF-IDF Feature Importance (Most Important Words)**
vectorizer = model_pipeline.named_steps['tfidfvectorizer']
model = model_pipeline.named_steps['logisticregression']

feature_names = np.array(vectorizer.get_feature_names_out())
sorted_coef_index = model.coef_[0].argsort()

top_features = 20
plt.figure(figsize=(10, 5))
plt.barh(feature_names[sorted_coef_index[-top_features:]], model.coef_[0][sorted_coef_index[-top_features:]], color='blue')
plt.xlabel("TF-IDF Importance")
plt.ylabel("Word")
plt.title("Top Words Contributing to Classification")
plt.show()

# Load model for inference
model_pipeline = joblib.load("fake_news_pipeline.pkl")

# Function for making predictions
def predict_news(texts):
    if isinstance(texts, str):  # Convert single input into list
        texts = [texts]
    predictions = model_pipeline.predict(texts)
    return ["Real News" if pred == 1 else "Fake News" for pred in predictions]

# Test sample predictions
sample_texts = [
    "Breaking news: Scientists discover a new planet similar to Earth!",
    "The president was caught in a major scandal, says unknown source.",
]
predictions = predict_news(sample_texts)

for text, prediction in zip(sample_texts, predictions):
    print(f"\nText: {text}\nPrediction: {prediction}")
